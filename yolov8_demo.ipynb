{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (8.0.110)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from ultralytics) (4.7.0.72)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from ultralytics) (9.3.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from ultralytics) (0.16.0.dev20230529+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from ultralytics) (2.1.0.dev20230528+cu118)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from ultralytics) (5.4.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (0.10.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (5.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (4.39.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.24.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.7.0->ultralytics) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.7.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.7.0->ultralytics) (3.0rc1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.7.0->ultralytics) (2023.4.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->ultralytics) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\tim van kesteren\\appdata\\roaming\\python\\python38\\site-packages (from sympy->torch>=1.7.0->ultralytics) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import cv2\n",
    "    from ultralytics import YOLO\n",
    "    from ultralytics.yolo.v8.detect.predict import DetectionPredictor\n",
    "    import torchvision.ops as ops\n",
    "    import colorsys\n",
    "    import datetime\n",
    "    import time\n",
    "    import mediapipe as mp\n",
    "    from moviepy.editor import VideoFileClip\n",
    "    \n",
    "    print('All packages imported')\n",
    "except:\n",
    "    !pip install cv2 ultralytics torchvision moviepy mediapipe\n",
    "    import cv2\n",
    "    from ultralytics import YOLO\n",
    "    from ultralytics.yolo.v8.detect.predict import DetectionPredictor\n",
    "    import torchvision.ops as ops\n",
    "    import colorsys\n",
    "    import datetime\n",
    "    import time\n",
    "    import mediapipe as mp\n",
    "    from moviepy.editor import VideoFileClip\n",
    "    print('Some packages were not installed, installed and imported')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resize input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code that converts the resolution of a video to 800x400:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_video(input_path, output_path, width, height):\n",
    "    video = cv2.VideoCapture(input_path)\n",
    "    success, frame = video.read()\n",
    "    if not success:\n",
    "        raise ValueError(\"Kan de video niet lezen\")\n",
    "\n",
    "    # Krijg de oorspronkelijke breedte en hoogte van de video\n",
    "    original_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Bereken de schaalverhouding\n",
    "    scale_ratio = min(width / original_width, height / original_height)\n",
    "\n",
    "    # Bereken het nieuwe formaat\n",
    "    new_width = int(original_width * scale_ratio)\n",
    "    new_height = int(original_height * scale_ratio)\n",
    "\n",
    "    # Maak een VideoWriter-object om het uitvoerbestand te maken\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_video = cv2.VideoWriter(output_path, fourcc, 30.0, (new_width, new_height))\n",
    "\n",
    "    while success:\n",
    "        # Verklein het frame naar het nieuwe formaat\n",
    "        resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "        # Schrijf het verkleinde frame naar het uitvoerbestand\n",
    "        output_video.write(resized_frame)\n",
    "\n",
    "        # Lees het volgende frame\n",
    "        success, frame = video.read()\n",
    "\n",
    "    # Sluit de video-objecten\n",
    "    video.release()\n",
    "    output_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pad naar het invoerbestand\n",
    "# input_file = 'vid.mp4'\n",
    "\n",
    "# # Pad naar het uitvoerbestand\n",
    "# output_file = 'vid_res.mp4'\n",
    "\n",
    "# # Breedte en hoogte voor het formaat wijzigen\n",
    "# target_width = 640\n",
    "# target_height = 360\n",
    "\n",
    "# resize_video(input_file, output_file, target_width, target_height)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply the model on the converted video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"videos/vid2.mp4\"  # video\n",
    "threshold = 0.70  # detection threshold\n",
    "model = YOLO('models/paddletracker v1.7.pt')\n",
    "mp_pose = mp.solutions.pose\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pose analysis done by Google Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_analysis(image):\n",
    "    with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        image_height, image_width, _ = image.shape\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        if results.pose_landmarks:\n",
    "            # Connect landmarks\n",
    "            mp_drawing = mp.solutions.drawing_utils\n",
    "            annotated_image = image.copy()\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "            )\n",
    "            return annotated_image\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paddle detection (incl. lights) done by Yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paddle_analysis(frame):\n",
    "    result = model.predict(frame, threshold)\n",
    "    result = list(result) # Convert to a list\n",
    "    boxes = result[0].boxes.xyxy.cuda()\n",
    "    scores = result[0].boxes.conf.cuda()\n",
    "    class_ids = result[0].names \n",
    "    \n",
    "    for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "        \n",
    "        if score >= threshold:\n",
    "            box = [int(i) for i in box]\n",
    "            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (255,255,255), 2)\n",
    "            cv2.putText(frame, f\"{class_id}\", (box[0], box[3] + 36), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyse_video():\n",
    "    cap = cv2.VideoCapture(INPUT)\n",
    "    prev_timestamp = time.time()\n",
    "\n",
    "    # Initialiseren van de Mediapipe Pose Detection\n",
    "    mp_pose = mp.solutions.pose\n",
    "    with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            img = paddle_analysis(frame)\n",
    "            img = pose_analysis(img)\n",
    "\n",
    "            current_timestamp = time.time()\n",
    "            time_delta = current_timestamp - prev_timestamp\n",
    "            \n",
    "            if img is None or img.shape[0] == 0 or img.shape[1] == 0:\n",
    "                break\n",
    "\n",
    "            # # Voer pose detection uit op het frame\n",
    "            # img = pose_analysis(img)\n",
    "\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            prev_timestamp = current_timestamp\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 40.5ms\n",
      "Speed: 6.5ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 12.5ms\n",
      "Speed: 4.5ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 9.5ms\n",
      "Speed: 6.5ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 9.5ms\n",
      "Speed: 4.0ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 9.5ms\n",
      "Speed: 4.5ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 10.5ms\n",
      "Speed: 4.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 9.5ms\n",
      "Speed: 3.5ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 17.5ms\n",
      "Speed: 3.0ms preprocess, 17.5ms inference, 4.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 17.5ms\n",
      "Speed: 4.6ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 19.0ms\n",
      "Speed: 5.0ms preprocess, 19.0ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 18.5ms\n",
      "Speed: 3.7ms preprocess, 18.5ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 43.5ms\n",
      "Speed: 5.0ms preprocess, 43.5ms inference, 8.6ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 40.0ms\n",
      "Speed: 4.0ms preprocess, 40.0ms inference, 6.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 36.0ms\n",
      "Speed: 4.0ms preprocess, 36.0ms inference, 6.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 36.5ms\n",
      "Speed: 13.6ms preprocess, 36.5ms inference, 16.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 30.5ms\n",
      "Speed: 3.5ms preprocess, 30.5ms inference, 5.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 35.1ms\n",
      "Speed: 4.0ms preprocess, 35.1ms inference, 4.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 39.9ms\n",
      "Speed: 3.5ms preprocess, 39.9ms inference, 5.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 38.0ms\n",
      "Speed: 4.5ms preprocess, 38.0ms inference, 7.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 35.5ms\n",
      "Speed: 3.5ms preprocess, 35.5ms inference, 3.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 36.5ms\n",
      "Speed: 4.5ms preprocess, 36.5ms inference, 4.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 35.8ms\n",
      "Speed: 6.6ms preprocess, 35.8ms inference, 10.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 31.0ms\n",
      "Speed: 5.0ms preprocess, 31.0ms inference, 6.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 36.5ms\n",
      "Speed: 4.6ms preprocess, 36.5ms inference, 5.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 34.2ms\n",
      "Speed: 3.0ms preprocess, 34.2ms inference, 6.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 33.5ms\n",
      "Speed: 4.0ms preprocess, 33.5ms inference, 3.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 33.5ms\n",
      "Speed: 6.5ms preprocess, 33.5ms inference, 7.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 34.1ms\n",
      "Speed: 5.0ms preprocess, 34.1ms inference, 4.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 33.5ms\n",
      "Speed: 6.5ms preprocess, 33.5ms inference, 9.6ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 33.1ms\n",
      "Speed: 4.0ms preprocess, 33.1ms inference, 3.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 36.1ms\n",
      "Speed: 4.0ms preprocess, 36.1ms inference, 6.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 30.5ms\n",
      "Speed: 4.6ms preprocess, 30.5ms inference, 4.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 32.1ms\n",
      "Speed: 4.6ms preprocess, 32.1ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 34.5ms\n",
      "Speed: 4.5ms preprocess, 34.5ms inference, 3.6ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 32.0ms\n",
      "Speed: 4.5ms preprocess, 32.0ms inference, 4.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 38.0ms\n",
      "Speed: 11.5ms preprocess, 38.0ms inference, 12.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 7.5ms\n",
      "Speed: 5.0ms preprocess, 7.5ms inference, 3.6ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 8.6ms\n",
      "Speed: 3.6ms preprocess, 8.6ms inference, 2.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 9.6ms\n",
      "Speed: 4.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 9.6ms\n",
      "Speed: 3.0ms preprocess, 9.6ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 9.5ms\n",
      "Speed: 3.0ms preprocess, 9.5ms inference, 4.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 7.0ms\n",
      "Speed: 3.6ms preprocess, 7.0ms inference, 3.6ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 8.0ms\n",
      "Speed: 4.5ms preprocess, 8.0ms inference, 3.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 8.5ms\n",
      "Speed: 3.5ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 8.5ms\n",
      "Speed: 3.0ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 7.6ms\n",
      "Speed: 4.0ms preprocess, 7.6ms inference, 4.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 8.5ms\n",
      "Speed: 4.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 7.5ms\n",
      "Speed: 3.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 42.0ms\n",
      "Speed: 10.0ms preprocess, 42.0ms inference, 12.2ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 34.3ms\n",
      "Speed: 6.0ms preprocess, 34.3ms inference, 5.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 480x800 2 light_neutrals, 1 paddle, 40.7ms\n",
      "Speed: 17.0ms preprocess, 40.7ms inference, 10.5ms postprocess per image at shape (1, 3, 800, 800)\n"
     ]
    }
   ],
   "source": [
    "analyse_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
